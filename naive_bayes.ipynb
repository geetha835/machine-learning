{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84cedc35-6fed-4eff-a244-ce23b9f176e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  target       category\n",
      "0     From: degroff@netcom.com (21012d)\\nSubject: Re...       2      sci.space\n",
      "1     From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
      "2     From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...       0    alt.atheism\n",
      "3     From: capelli@vnet.IBM.COM (Ron Capelli)\\nSubj...       1  comp.graphics\n",
      "4     From: henry@zoo.toronto.edu (Henry Spencer)\\nS...       2      sci.space\n",
      "...                                                 ...     ...            ...\n",
      "1652  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
      "1653  From: renes@ecpdsharmony.cern.ch (Rene S. Dutc...       1  comp.graphics\n",
      "1654  From: xrcjd@resolve.gsfc.nasa.gov (Charles J. ...       2      sci.space\n",
      "1655  From: dietz@cs.rochester.edu (Paul Dietz)\\nSub...       2      sci.space\n",
      "1656  From: jhwitten@cs.ruu.nl (Jurriaan Wittenberg)...       2      sci.space\n",
      "\n",
      "[1657 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/home/user/Downloads/nlp_train.csv\"  # Update this path if needed\n",
    "df2 = pd.read_csv(file_path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44f788bb-e891-4077-848d-22f2bb367aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rec.autos', 'comp.sys.mac.hardware', 'comp.graphics', 'sci.space',\n",
       "       'talk.politics.guns', 'sci.med', 'comp.sys.ibm.pc.hardware',\n",
       "       'comp.os.ms-windows.misc', 'rec.motorcycles', 'talk.religion.misc',\n",
       "       'misc.forsale', 'alt.atheism', 'sci.electronics', 'comp.windows.x',\n",
       "       'rec.sport.hockey', 'rec.sport.baseball', 'soc.religion.christian',\n",
       "       'talk.politics.mideast', 'talk.politics.misc', 'sci.crypt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4982c5a-608e-46d8-beab-67db60263f43",
   "metadata": {},
   "source": [
    "## print(df.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ab33074-50fa-4696-8a76-5eee79099da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4b534c5-e3bd-402a-b2d6-36b75ddd258c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d462490-b276-4054-9506-cdb9e4b3cae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.sys.mac.hardware'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c759d7f-e196-480f-9198-696d5d94be13",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (710296944.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[56], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    vocab=(I,love,Programming,is,interesting,pizza,very,much)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#countvectorizer\n",
    "d1=\"I love Programming\"\n",
    "d2=\"Programming is interesting\"\n",
    "d3=\"I love pizza very very much\"\n",
    "vocab=(I,love,Programming,is,interesting,pizza,very,much)\n",
    "d1=[1,1,1,0,0,0,0,0]\n",
    "d2=[0,0,1,1,1,0,0,0]\n",
    "d3=[1,1,0,0,0,1,2,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36f9b853-a278-42c0-b606-1c53774140e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 2, 'programming': 5, 'is': 1, 'interesting': 0, 'pizza': 4, 'very': 6, 'much': 3}\n",
      "[[0 0 1 0 0 1 0]\n",
      " [1 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "d1=\"I love Programming\"\n",
    "d2=\"Programming Is interesting\"\n",
    "d3=\"I love pizza very very much\"\n",
    "documents=[d1,d2,d3]\n",
    "vectorizer=CountVectorizer()\n",
    "x=vectorizer.fit_transform(documents)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6285fe84-561e-4d51-938f-ade11098e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  target       category\n",
      "0     From: degroff@netcom.com (21012d)\\nSubject: Re...       2      sci.space\n",
      "1     From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
      "2     From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...       0    alt.atheism\n",
      "3     From: capelli@vnet.IBM.COM (Ron Capelli)\\nSubj...       1  comp.graphics\n",
      "4     From: henry@zoo.toronto.edu (Henry Spencer)\\nS...       2      sci.space\n",
      "...                                                 ...     ...            ...\n",
      "1652  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
      "1653  From: renes@ecpdsharmony.cern.ch (Rene S. Dutc...       1  comp.graphics\n",
      "1654  From: xrcjd@resolve.gsfc.nasa.gov (Charles J. ...       2      sci.space\n",
      "1655  From: dietz@cs.rochester.edu (Paul Dietz)\\nSub...       2      sci.space\n",
      "1656  From: jhwitten@cs.ruu.nl (Jurriaan Wittenberg)...       2      sci.space\n",
      "\n",
      "[1657 rows x 3 columns]\n",
      "                                                   text  target       category\n",
      "0     From: mccall@mksol.dseg.ti.com (fred j mccall ...       2      sci.space\n",
      "1     From: \"Changyaw Wang\" <wangc@cs.indiana.edu>\\n...       1  comp.graphics\n",
      "2     From: lioness@maple.circa.ufl.edu\\nSubject: Te...       1  comp.graphics\n",
      "3     From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...       1  comp.graphics\n",
      "4     From: Ad-Robot@bobsbox.rent.com (Robotic Posti...       1  comp.graphics\n",
      "...                                                 ...     ...            ...\n",
      "1097  From: malek@pi.titech.ac.jp (Zidouri Abdelmale...       1  comp.graphics\n",
      "1098  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0    alt.atheism\n",
      "1099  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...       0    alt.atheism\n",
      "1100  From: beck@irzr17.inf.tu-dresden.de (Andre Bec...       1  comp.graphics\n",
      "1101  From: 18084TM@msu.edu (Tom)\\nSubject: Billboar...       2      sci.space\n",
      "\n",
      "[1102 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#2. import 20 newsgroup dataset from scikit learn datasets\n",
    "df=pd.read_csv(\"/home/user/Downloads/newsgroups_train.csv\")\n",
    "df1=pd.read_csv(\"/home/user/Downloads/newsgroups_test.csv\")\n",
    "print(df)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b61c2051-7cc8-4942-a136-0d8631bb3a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique target names (labels):\n",
      "['sci.space' 'comp.graphics' 'alt.atheism']\n"
     ]
    }
   ],
   "source": [
    "#print new training set target names(labels)\n",
    "unique_labels = df[\"category\"].unique()\n",
    "\n",
    "# Print the unique labels\n",
    "print(\"Unique target names (labels):\")\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "971ffbd1-aab4-4712-8e56-7617dbb8aaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: henry@zoo.toronto.edu (Henry Spencer)\n",
      "Subject: Re: TRUE \"GLOBE\", Who makes it?\n",
      "Organization: U of Toronto Zoology\n",
      "Lines: 12\n",
      "\n",
      "In article <bill.047m@xpresso.UUCP> bill@xpresso.UUCP (Bill Vance) writes:\n",
      ">It has been known for quite a while that the earth is actually more pear\n",
      ">shaped than globular/spherical.  Does anyone make a \"globe\" that is accurate\n",
      ">as to actual shape, landmass configuration/Long/Lat lines etc.?\n",
      "\n",
      "I don't think you're going to be able to see the differences from a sphere\n",
      "unless they are greatly exaggerated.  Even the equatorial bulge is only\n",
      "about 1 part in 300 -- you'd never notice a 1mm error in a 30cm globe --\n",
      "and the other deviations from spherical shape are much smaller.\n",
      "-- \n",
      "SVR4 resembles a high-speed collision   | Henry Spencer @ U of Toronto Zoology\n",
      "between SVR3 and SunOS.    - Dick Dunn  |  henry@zoo.toronto.edu  utzoo!henry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print news trining data of 5th article\n",
    "fifth_article_text = df.iloc[4,0]\n",
    "print(fifth_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbd59293-b248-4030-9c86-137b09f7a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data: (1657, 3)\n",
      "Shape of the targets: (1657, 1)\n"
     ]
    }
   ],
   "source": [
    "#11.print shape of data and targets\n",
    "data_shape = df.shape\n",
    "\n",
    "# Get the shape of the 'target' column\n",
    "target_shape = df[['target']].shape\n",
    "\n",
    "print(f\"Shape of the data: {data_shape}\")\n",
    "print(f\"Shape of the targets: {target_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c44c2c04-2545-4d14-bf38-693dd0cc98a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#13 by using count vectorizer train data into numerical format considering\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(df['text'])\n",
    "print(X_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a11a725f-08bb-43b3-bffd-363798e385bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB()\n",
      "[[-4.79164975 -3.69303746 -6.17794411 ... -5.48479693 -6.17794411\n",
      "  -6.17794411]\n",
      " [-3.32879735 -3.88841314 -6.37331979 ... -6.37331979 -5.2747075\n",
      "  -5.68017261]\n",
      " [-3.29751895 -2.65089179 -5.28994912 ... -6.38856141 -6.38856141\n",
      "  -6.38856141]]\n"
     ]
    }
   ],
   "source": [
    "#14 use bernoull NB FOR taining\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "y_train = df['category']\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "print(bnb)\n",
    "#just to check whether the bernouli is  lassified are not\n",
    "print(bnb.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b994ccb-ba43-46bf-9408-e17da40a6d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#15 by using count vectorizer train data into numerical format considering\n",
    "vectorizer = CountVectorizer()\n",
    "X_test = vectorizer.fit_transform(df1['text'])\n",
    "print(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60e211d9-9478-4e41-b2ee-c48475a86aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels for the testing set:\n",
      "['sci.space' 'comp.graphics' 'comp.graphics' ... 'alt.atheism'\n",
      " 'comp.graphics' 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "#16.predict target labels for testing set\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training data\n",
    "X_train = vectorizer.fit_transform(df['text'])\n",
    "y_train = df['category']\n",
    "\n",
    "# Transform the testing data using the already fitted vectorizer\n",
    "X_test = vectorizer.transform(df1['text'])\n",
    "y_test = df1['category']\n",
    "\n",
    "# Initialize the Bernoulli Naive Bayes classifier\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Train the classifier\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target labels for the testing set\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "# Display the predicted labels\n",
    "print(\"Predicted labels for the testing set:\")\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "000df326-910b-4b5d-a2b6-655b83ff974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier on the test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "#17 find accuracy score on test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the classifier on the test set: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cabee187-492c-4305-baae-535222787b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.97      0.95      0.96       319\n",
      "comp.graphics       0.97      0.92      0.94       389\n",
      "    sci.space       0.91      0.97      0.94       394\n",
      "\n",
      "     accuracy                           0.95      1102\n",
      "    macro avg       0.95      0.95      0.95      1102\n",
      " weighted avg       0.95      0.95      0.95      1102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#18.used tfidfvectorizer instead of count vectorizer and use multinomial NB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "df3=pd.read_csv(\"/home/user/Downloads/newsgroups_train.csv\")\n",
    "df4=pd.read_csv(\"/home/user/Downloads/newsgroups_test.csv\")\n",
    "# Split the data we can't take directly above train and teat data because already we convert it into numeric\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df['text'])\n",
    "y_train = df['category']\n",
    "# Fit and transform the training data\n",
    "X_test = vectorizer.transform(df1['text'])\n",
    "y_test = df1['category']\n",
    "\n",
    "\n",
    "# Initialize and train the MultinomialNB classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "41c37173-bd17-45f2-80f9-ed2d25876aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.97      0.95      0.96       319\n",
      "comp.graphics       0.97      0.92      0.94       389\n",
      "    sci.space       0.91      0.97      0.94       394\n",
      "\n",
      "     accuracy                           0.95      1102\n",
      "    macro avg       0.95      0.95      0.95      1102\n",
      " weighted avg       0.95      0.95      0.95      1102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#18.used tfidfvectorizer instead of count vectorizer and use multinomial NB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "df3=pd.read_csv(\"/home/user/Downloads/newsgroups_train.csv\")\n",
    "df4=pd.read_csv(\"/home/user/Downloads/newsgroups_test.csv\")\n",
    "# Split the data we can't take directly above train and teat data because already we convert it into numeric\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df3['text'])\n",
    "y_train = df3['category']\n",
    "# Fit and transform the training data\n",
    "X_test = vectorizer.transform(df4['text'])\n",
    "y_test = df4['category']\n",
    "\n",
    "\n",
    "# Initialize and train the MultinomialNB classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96cd08dc-41ee-4640-9e40-a3cf91801303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "#19.find test data accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7d8f11c-72a6-4907-9eee-bfeac7737e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.98      0.94      0.96       319\n",
      "comp.graphics       0.96      0.95      0.96       389\n",
      "    sci.space       0.93      0.97      0.95       394\n",
      "\n",
      "     accuracy                           0.96      1102\n",
      "    macro avg       0.96      0.95      0.96      1102\n",
      " weighted avg       0.96      0.96      0.96      1102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#20.try with avoiding stopwords and repeat the same\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "df3=pd.read_csv(\"/home/user/Downloads/newsgroups_train.csv\")\n",
    "df4=pd.read_csv(\"/home/user/Downloads/newsgroups_test.csv\")\n",
    "# Split the data we can't take directly above train and teat data because already we convert it into numeric\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(df3['text'])\n",
    "y_train = df3['category']\n",
    "# Fit and transform the training data\n",
    "X_test = vectorizer.transform(df4['text'])\n",
    "y_test = df4['category']\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb364658-529c-414c-b3ee-c38fe2e4b6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
